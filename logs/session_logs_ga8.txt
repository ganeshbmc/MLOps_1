Script started on 2025-08-04 21:36:23+05:30 [TERM="xterm-256color" TTY="/dev/pts/2" COLUMNS="132" LINES="50"]
[?2004h(base) jupyter@instance-20250527-224052:~/iris_pipeline$ condat[K ativate[K[K[K[K[K[Kctivate iris_env_c
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "($date) - Let us check git status before b[Kporc[K[K[Kroceeding."[1@W[1@e[1@e[1@k[1@ [1@8[1@ [1@G[1@A Let us check git status before proceeding." [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CbLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CeLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CgLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CiLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CnLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[CsLet us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.Let us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C Let us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

[?2004l() - Week 8 GA begins. Let us check git status before proceeding.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "($date) - Week 8 GA begins. Let us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cdate) - Week 8 GA begins. Let us check git status before procee[1Pding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C$(date) - Week 8 GA begins. Let us check git status before proceeding."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

[?2004lMon Aug  4 21:38:04 IST 2025 - Week 8 GA begins. Let us check git status before proceeding.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ touuc[K[Kch logs/log_push_ga8.txt
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat logs/log_push_ga8.txt 
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat logs/log_push_ga8.txt touch logs/log_push_ga8.txtecho "$(date) - Week 8 GA begins. Let us check git status before proceeding." >> logs/log_push_ga8.txt 
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "$(date) - Week 8 GA begins. Let us check git status before proceeding." >> logs/log_push_ga8.txt [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[43Pcat logs/log_push_ga8.txt 
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004lMon Aug  4 21:38:55 IST 2025 - Week 8 GA begins. Let us check git status before proceeding.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git sat[K[Ktatus
[?2004lOn branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   dvc.lock[m
	[31mmodified:   helpers/__pycache__/feast_utils.cpython-310.pyc[m
	[31mmodified:   helpers/__pycache__/mlflow_dvc_utils.cpython-310.pyc[m

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31m.ipynb_checkpoints/dvc-checkpoint.lock[m
	[31mlogs/log_push_ga8.txt[m
	[31mlogs/session_logs_ga8.txt[m

no changes added to commit (use "git add" and/or "git commit -a")
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "$(date) - DD[K[K[K Rest of the work will be done on brancked [K[K[K[Kh named 'hacker '. This branch will be from main branch at commit [7md96f15b44460672cd7da64ee74e90e987d7f7498[27md96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th."[K[K which is the finnal [K[K[K[Kal commit for  GA5. Idd[Keas[K isto [K[K[K start GA8 from this stage as GA6 and ga[K[KGA77[K were impl[K[K[K[Kdifferent and ran from separate folder excep t[K[Kt for the github actions test .yml file."
[?2004lMon Aug  4 21:43:39 IST 2025 - Rest of the work will be done on branch named 'hacker'. This branch will be from main branch at commit d96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th which is the final commit for GA5. Idea is start GA8 from this stage as GA6 and GA7 were different and ran from separate folder except for the github actions test.yml file.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "$(date) - Rest of the work will be done on branch named 'hacker'. This branch will be from main branch at commit d96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th which is the final commit for GA5. Idea is start GA8 from this stage as GA6 and GA7 were different and ran from separate folder except for the github actions test.yml file." >> logs/log_push_ga8.txt 
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat logs/log_push_ga8.txt 
[?2004lMon Aug  4 21:38:55 IST 2025 - Week 8 GA begins. Let us check git status before proceeding.
Mon Aug  4 21:43:53 IST 2025 - Rest of the work will be done on branch named 'hacker'. This branch will be from main branch at commit d96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th which is the final commit for GA5. Idea is start GA8 from this stage as GA6 and GA7 were different and ran from separate folder except for the github actions test.yml file.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   dvc.lock[m
	[31mmodified:   helpers/__pycache__/feast_utils.cpython-310.pyc[m
	[31mmodified:   helpers/__pycache__/mlflow_dvc_utils.cpython-310.pyc[m

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31m.ipynb_checkpoints/dvc-checkpoint.lock[m
	[31mlogs/log_push_ga8.txt[m
	[31mlogs/session_logs_ga8.txt[m

no changes added to commit (use "git add" and/or "git commit -a")
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git add .
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git commit -m "Uud[K[Kpdating main before forking a new branch 'hacker' for  GA88"[K[K."
[?2004l[main 6324a41] Updating main before forking a new branch 'hacker' for GA8.
 6 files changed, 222 insertions(+), 21 deletions(-)
 create mode 100644 .ipynb_checkpoints/dvc-checkpoint.lock
 create mode 100644 logs/log_push_ga8.txt
 create mode 100644 logs/session_logs_ga8.txt
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ gi tpus[K[K[K[K[Kt push origin manin[K[K[Kin
[?2004lEnumerating objects: 18, done.
Counting objects:   5% (1/18)Counting objects:  11% (2/18)Counting objects:  16% (3/18)Counting objects:  22% (4/18)Counting objects:  27% (5/18)Counting objects:  33% (6/18)Counting objects:  38% (7/18)Counting objects:  44% (8/18)Counting objects:  50% (9/18)Counting objects:  55% (10/18)Counting objects:  61% (11/18)Counting objects:  66% (12/18)Counting objects:  72% (13/18)Counting objects:  77% (14/18)Counting objects:  83% (15/18)Counting objects:  88% (16/18)Counting objects:  94% (17/18)Counting objects: 100% (18/18)Counting objects: 100% (18/18), done.
Delta compression using up to 2 threads
Compressing objects:   9% (1/11)Compressing objects:  18% (2/11)Compressing objects:  27% (3/11)Compressing objects:  36% (4/11)Compressing objects:  45% (5/11)Compressing objects:  54% (6/11)Compressing objects:  63% (7/11)Compressing objects:  72% (8/11)Compressing objects:  81% (9/11)Compressing objects:  90% (10/11)Compressing objects: 100% (11/11)Compressing objects: 100% (11/11), done.
Writing objects:   9% (1/11)Writing objects:  18% (2/11)Writing objects:  27% (3/11)Writing objects:  36% (4/11)Writing objects:  45% (5/11)Writing objects:  54% (6/11)Writing objects:  63% (7/11)Writing objects:  72% (8/11)Writing objects:  81% (9/11)Writing objects: 100% (11/11)Writing objects: 100% (11/11), 3.21 KiB | 1.07 MiB/s, done.
Total 11 (delta 7), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas:   0% (0/7)[Kremote: Resolving deltas:  14% (1/7)[Kremote: Resolving deltas:  28% (2/7)[Kremote: Resolving deltas:  42% (3/7)[Kremote: Resolving deltas:  57% (4/7)[Kremote: Resolving deltas:  71% (5/7)[Kremote: Resolving deltas:  85% (6/7)[Kremote: Resolving deltas: 100% (7/7)[Kremote: Resolving deltas: 100% (7/7), completed with 6 local objects.[K
To https://github.com/ganeshbmc/MLOps_1.git
   0ac1b14..6324a41  main -> main
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git log --oneline
[?2004l[?1h=[33m6324a41[m[33m ([m[1;36mHEAD -> [m[1;32mmain[m[33m, [m[1;31morigin/main[m[33m)[m Updating main before forking a new branch 'hacker' for GA8.[m
[33m0ac1b14[m Merge pull request #26 from ganeshbmc/dev[m
[33mbf67f86[m[33m ([m[1;31morigin/dev[m[33m, [m[1;32mdev[m[33m)[m Successfully completed week 7 demo. No changes to github actions. Minor changes in log files added.[m
[33m6c77d28[m Successfully completed week 7 demo. No changes to github actions.[m
[33m6bcda85[m Week 7 GA complete[m
[33m80be7bb[m Merge pull request #25 from ganeshbmc/dev[m
[33m6ee2181[m Checking github actions set up in week 5. Remember that GitHub Actions does not use file from observabiliyt_demo yet.[m
[33macc22a2[m Merge pull request #24 from ganeshbmc/dev[m
[33m11e0dc1[m Docker up and running after file edits in observability_demo files. Checked GET/PUSH calls.[m
[33mc2fe5a9[m Merge pull request #23 from ganeshbmc/dev[m
[33m90a8551[m Created new folder for week 7 work on monitoring, logging, trace and observability. Added the files. Need to check and edit [m [33m[mone by one.[m
[33mea94c9b[m Pushing log to check week 6 CI/CD pipeline[m
[33m0a0a8a0[m minor changes to sesion log[m
[33m9d835e4[m minor changes to log file[m
[33m3ccee3f[m Merge branch 'main' of https://github.com/ganeshbmc/MLOps_1[m
[33m7260e33[m Organized the log files into log folder and renamed them week wise.[m
[33m401a72b[m Merge pull request #22 from ganeshbmc/dev[m
[33m9e575bc[m GA6 session ended[m
[33m869271c[m Successful GA6 demo[m
[33mcd3ac9a[m Merge pull request #21 from ganeshbmc/dev[m
[33mdc0d6b7[m CI/CD pipeline already successful. Now adding some comments to PR using CML.[m
[33m48967f2[m Merge pull request #20 from ganeshbmc/dev[m
[33m2ca5537[m Eleventh attempt of CI/CD combo pipeline.[m
[33m674438a[m Tenth attempt of CI/CD combo pipeline.[m
[33mf068f7d[m Ninth attempt of CI/CD combo pipeline.[m
[33mf0244f7[m Eighth attempt of CI/CD combo pipeline.[m
[33mb76f75c[m Seventh attempt of CI/CD combo pipeline.[m
[33mf419c18[m Sixth attempt of CI/CD combo pipeline.[m
[33me9da3a9[m Fifth attempt of CI/CD combo pipeline.[m
[33m70fe85e[m Fourth attempt of CI/CD combo pipeline.[m
[33md5c545c[m Third attempt of CI/CD combo pipeline.[m
[33m564e1a7[m Second attempt of CI/CD combo pipeline.[m
[33m1487ccd[m Trying CI/CD combo pipeline for the first time. Not sure about correct authorizations. Fingers crossed.[m
[33mc6949ba[m Merge pull request #19 from ganeshbmc/dev[m
[33m0d03572[m Kubernetes successfully set up. Deployed the iris-api docker container; had to change port from 8200 to 80 in Dockerfile. Co[m [33m[muld successfully test the deployment using postman.[m
[33m1d7f9a6[m Merge pull request #18 from ganeshbmc/dev[m
[33m838aaf6[m Docker set up complete. Checked locally using postman.[m
[33mcc7cb7e[m Merge pull request #17 from ganeshbmc/dev[m
[33m32ff8d2[m FastAPI app set up complete and tested with uvicorn locally. Used label encoder in addition to model joblib file[m
[33m467af6c[m Merge pull request #16 from ganeshbmc/dev[m
[33mb732b45[m Modified test file again and changed back the file path to be relative to root[m
[33mef601b2[m Changed gitignore file and added specific files to be tracked by dvc[m
[33m4b7f2dd[m Modified test files to point to correct file paths[m
[33m36cdd4f[m Checking GitHub Actions set up in GA5 before beginning GA6[m
[33ma0955f0[m Checking GitHub Actions set up in GA5 before beginning GA6[m
[33md96f15b[m Merge pull request #15 from ganeshbmc/dev[m
[33m2ba4dea[m GA5 completed successfully[m
:[K[K[?1l>[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git checkout hacker [K-hackerbhacker hacker hacker[1Phacker[C[C[C[C[C[C [7md96f15b44460672cd7da64ee74e90e987d7f7498[27mScript started on 2025-08-05 20:44:25+05:30 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="132" LINES="50"]
[?2004h(base) jupyter@instance-20250527-224052:~/iris_pipeline$ conda activate iris_env_c
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch hacker
Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31mscripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[31mscripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[31mscripts/poison_features.py[m
	[31mscripts/poison_labels.py[m

nothing added to commit but untracked files present (use "git add" to track)
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ dvc repro
[?2004l!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    'data/iris_entity.csv.dvc' didn't change, skipping
!Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'prepare_data' didn't change, skipping
!Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2024.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'train_2024' didn't change, skipping
!Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2024.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'evaluate_2024' didn't change, skipping
!Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023_2024.json                                   |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'train_2023_2024' didn't change, skipping
!Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023_2024.json                                      |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'evaluate_2023_2024' didn't change, skipping
!Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'train_2023' didn't change, skipping
!Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    Stage 'evaluate_2023' didn't change, skipping
Data and pipelines are up to date.
[0m[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ mv .github/workflows/test.yml .github/workflows/test.yml [K.tmp
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ ls .github/workflows/
[?2004lhacker_ci_cml_ga8.yml  test.yml.tmp
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch hacker
Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mdeleted:    .github/workflows/test.yml[m
	[31mmodified:   logs/session_logs_ga8.txt[m

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	[31m.github/workflows/test.yml.tmp[m
	[31mscripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[31mscripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[31mscripts/poison_features.py[m
	[31mscripts/poison_labels.py[m

no changes added to commit (use "git add" and/or "git commit -a")
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat .github/wwt[K[K[Kworkflows/test.yml.tmp 
[?2004lname: CI/CD with CML

on: [pull_request]

permissions:
  contents: read
  pull-requests: write

jobs:
  run-tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          environment-file: environment.yml
          activate-environment: iris_env_c
          auto-activate-base: false
          miniforge-variant: Miniforge3

      - name: Install required Python packages (pytest, dvc-gs)
        shell: bash -l {0}
        run: |
          conda activate iris_env_c
          pip install pytest dvc-gs

      - name: Authenticate to Google Cloud
        run: |
          echo "$GCP_SERVICE_ACCOUNT_KEY" > gcp-key.json
          export GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
        shell: bash
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}


      - name: DVC Pull Data
        shell: bash -l {0}
        run: |
          export GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json
          conda activate iris_env_c
          dvc pull --force
          ls data/
          ls artifacts/

      - name: Run tests and create report
        shell: bash -l {0}
        run: |
          conda activate iris_env_c
          echo "## Test Report" > report.md
          pytest -s tests/ --tb=short -p no:warnings >> report.md || true

      - name: Set up CML
        uses: iterative/setup-cml@v2

      - name: Comment on PR with test results
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cml comment create report.md

      - name: Authenticate to Google Cloud and setup GKE
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: polar-pillar-461115-g2
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          install_components: 'gke-gcloud-auth-plugin' # Installs the GKE auth plugin
          # No need to explicitly install kubectl here, setup-gcloud can also handle it,
          # or it's often included with the gcloud SDK.

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker us-central1-docker.pkg.dev

      - name: Print current directory and contents
        run: |
          pwd
          ls -R

      - name: Build Docker Image
        run: |
          docker build -t us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api:latest docker_demo

      - name: Push Docker Image to Artifact Registry
        run: |
          docker push us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api:latest

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Get GKE credentials
        run: |
          gcloud container clusters get-credentials demo-gke-iris-cluster \
            --zone us-central1 \
            --project polar-pillar-461115-g2

      - name: Deploy latest image to GKE
        run: |
          kubectl set image deployment/demo-iris-workload iris-api-sha256-1=us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api:latest

      - name: Comment on PR that CD was successful
        shell: bash
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Extract LoadBalancer IP (if available)
          EXTERNAL_IP=$(kubectl get service demo-iris-workload-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          # Extract deployed image SHA digest
          IMAGE_DIGEST=$(kubectl get deployment demo-iris-workload -o=jsonpath='{.spec.template.spec.containers[0].image}' | cut -d'@' -f2)

          echo "## ✅ CD Success 🚀" > cd_success.md
          echo "" >> cd_success.md
          echo "✅ The Docker image was successfully built and pushed to Artifact Registry." >> cd_success.md
          echo "✅ Deployment to GKE cluster \`demo-gke-iris-cluster\` was completed." >> cd_success.md
          echo "" >> cd_success.md

          if [ -n "$EXTERNAL_IP" ]; then
            echo "**Access URL:** [http://$EXTERNAL_IP](http://$EXTERNAL_IP)" >> cd_success.md
          else
            echo "**Access URL:** LoadBalancer IP not yet available (may take a few seconds to provision)." >> cd_success.md
          fi

          echo "" >> cd_success.md
          echo "**Deployed Image Digest:** \`$IMAGE_DIGEST\`" >> cd_success.md

          cml comment create cd_success.md

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git add .[K[K[K[K[K[K[K[K[Kgit add .
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git commit -m "Chenckin[K[K[K[K[Kcking [K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kecho "$(data) - Check dvc pipeline, mlflow tracking and [K[K[K[Kbefore poisonning  [K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[Kin g d[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Kg  data."
[?2004lbash: data: command not found
 - Check dvc pipeline, mlflow tracking before poisoning data.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "$(data) - Check dvc pipeline, mlflow tracking before poisoning data."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C) - Check dvc pipeline, mlflow tracking before poisoning da[1Pta."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce) - Check dvc pipeline, mlflow tracking before poisoning data."[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

[?2004lTue Aug  5 21:05:10 IST 2025 - Check dvc pipeline, mlflow tracking before poisoning data.
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ echo "$(date) - Check dvc pipeline, mlflow tracking before poisoning data." >> logs/ki[K[Klog_push_ga8.txt 
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch hacker
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mrenamed:    .github/workflows/test.yml -> .github/workflows/test.yml.tmp[m
	[32mmodified:   logs/session_logs_ga8.txt[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[32mnew file:   scripts/poison_features.py[m
	[32mnew file:   scripts/poison_labels.py[m

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   logs/log_push_ga8.txt[m
	[31mmodified:   logs/session_logs_ga8.txt[m

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git [K[K[K[Kdvc repor[K[Kro --force
[?2004l!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      Verifying data sources in stage: 'data/iris_entity.csv.dvc'
!Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out data/iris_entity.csv|                                                                  |0/1 [00:00<?,    ?files/s]                                                                                                                                    
Running stage 'prepare_data':
> python scripts/prepare_data.py
/opt/conda/envs/iris_env_c/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name "vector_enabled" in "SqliteOnlineStoreConfig" shadows an attribute in parent "VectorStoreConfig"
  warnings.warn(
/opt/conda/envs/iris_env_c/lib/python3.10/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.
  warnings.warn(
/opt/conda/envs/iris_env_c/lib/python3.10/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.
  warnings.warn(
/opt/conda/envs/iris_env_c/lib/python3.10/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.
  warnings.warn(
/opt/conda/envs/iris_env_c/lib/python3.10/site-packages/feast/repo_config.py:268: DeprecationWarning: The serialization version 2 and below will be deprecated in the next release. Specifying `entity_key_serialization_version` to 3 is recommended.
  warnings.warn(
Data preparation completed.
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out data/train_2023.csv|                                                                   |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out data/train_2024.csv|                                                                   |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out data/train_2023_2024.csv|                                                              |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing data/test_2025.csv to cache|                                                             |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out data/test_2025.csv|                                                                    |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'train_2023':
> python scripts/train_with_mlflow_tracking.py --train_csv data/train_2023.csv --model_out artifacts/model_2023.joblib --metrics_out metrics/metrics_2023.json --experiment_name hpt_iris_2023
Registered model 'iris_rf_model' already exists. Creating a new version of this model...
2025/08/05 21:09:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris_rf_model, version 16
Created version '16' of model 'iris_rf_model'.
2025/08/05 21:09:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/08/05 21:09:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
🏃 View run training at: http://127.0.0.1:8100/#/experiments/623096368429982395/runs/563a42ef42744bc7ab2ac303df33455e
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/623096368429982395
Training complete. Model saved to artifacts/model_2023.joblib
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing artifacts/model_2023.joblib to cache|                                                    |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out artifacts/model_2023.joblib|                                                           |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out metrics/metrics_2023.json|                                                             |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'evaluate_2023':
> python scripts/evaluate_with_mlflow_tracking.py --model artifacts/model_2023.joblib --test_csv data/test_2025.csv --metrics_out metrics/eval_2023.json --experiment_name hpt_iris_2023
🏃 View run evaluation at: http://127.0.0.1:8100/#/experiments/623096368429982395/runs/12f28cf01d61443a8eae648acec6b83d
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/623096368429982395
Evaluation complete. Accuracy: 0.9333
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out metrics/eval_2023.json|                                                                |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'train_2024':
> python scripts/train_with_mlflow_tracking.py --train_csv data/train_2024.csv --model_out artifacts/model_2024.joblib --metrics_out metrics/metrics_2024.json --experiment_name hpt_iris_2024
Registered model 'iris_rf_model' already exists. Creating a new version of this model...
2025/08/05 21:09:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris_rf_model, version 17
Created version '17' of model 'iris_rf_model'.
2025/08/05 21:09:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/08/05 21:09:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
🏃 View run training at: http://127.0.0.1:8100/#/experiments/488791870818176583/runs/2236932deb074966b07da1d5abed65ee
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/488791870818176583
Training complete. Model saved to artifacts/model_2024.joblib
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2024.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing artifacts/model_2024.joblib to cache|                                                    |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out artifacts/model_2024.joblib|                                                           |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2024.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing metrics/metrics_2024.json to cache|                                                      |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out metrics/metrics_2024.json|                                                             |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'evaluate_2024':
> python scripts/evaluate_with_mlflow_tracking.py --model artifacts/model_2024.joblib --test_csv data/test_2025.csv --metrics_out metrics/eval_2024.json --experiment_name hpt_iris_2024
🏃 View run evaluation at: http://127.0.0.1:8100/#/experiments/488791870818176583/runs/a4b02c36f4ca47cdba1aa5564a368efb
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/488791870818176583
Evaluation complete. Accuracy: 0.9333
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2024.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2024.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out metrics/eval_2024.json|                                                                |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'train_2023_2024':
> python scripts/train_with_mlflow_tracking.py --train_csv data/train_2023_2024.csv --model_out artifacts/model_2023_2024.joblib --metrics_out metrics/metrics_2023_2024.json --experiment_name hpt_iris_2023_2024
Registered model 'iris_rf_model' already exists. Creating a new version of this model...
2025/08/05 21:09:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris_rf_model, version 18
Created version '18' of model 'iris_rf_model'.
2025/08/05 21:09:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/08/05 21:09:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
🏃 View run training at: http://127.0.0.1:8100/#/experiments/812192867355831474/runs/fc6dc3eaa267423bbe8acbf6a9641859
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/812192867355831474
Training complete. Model saved to artifacts/model_2023_2024.joblib
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023_2024.json                                   |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing artifacts/model_2023_2024.joblib to cache|                                               |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out artifacts/model_2023_2024.joblib|                                                      |0/1 [00:00<?,    ?files/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023_2024.json                                   |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Committing metrics/metrics_2023_2024.json to cache|                                                 |0/1 [00:00<?,     ?file/s]                                                                                                                                    !  0% Checking out metrics/metrics_2023_2024.json|                                                        |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

Running stage 'evaluate_2023_2024':
> python scripts/evaluate_with_mlflow_tracking.py --model artifacts/model_2023_2024.joblib --test_csv data/test_2025.csv --metrics_out metrics/eval_2023_2024.json --experiment_name hpt_iris_2023_2024
🏃 View run evaluation at: http://127.0.0.1:8100/#/experiments/812192867355831474/runs/42777e18504c4034a719fa07ac5a8a1a
🧪 View experiment at: http://127.0.0.1:8100/#/experiments/812192867355831474
Evaluation complete. Accuracy: 0.9500
!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023_2024.json                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023_2024.json                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !  0% Checking cache in '/home/jupyter/iris_pipeline/.dvc/cache/files/md5'|                               |0/? [00:00<?,    ?files/s]                                                                                                                                    !  0% Checking out metrics/eval_2023_2024.json|                                                           |0/1 [00:00<?,    ?files/s]                                                                                                                                    Updating lock file 'dvc.lock'

To track the changes with git, run:

	git add data/iris_entity.csv.dvc dvc.lock

To enable auto staging, run:

	dvc config core.autostage true
Use `dvc push` to send your updates to remote storage.
[0m[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ dvc status
[?2004l!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2024.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2024.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023_2024.json                                   |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023_2024.json                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/label_encoder_2023_2024.joblib                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/feast_iris_model.joblib                                |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/feast_iris_label_encoder.joblib                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/label_encoder_2023.joblib                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_sepal.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_petal.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/registry.db                                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_sepal.parquet                                          |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/online_features_iris.csv                                    |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_petal.parquet                                          |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/online_store.db                                             |0.00 [00:00,     ?file/s]                                                                                                                                    .ipynb_checkpoints/data-checkpoint.dvc:
	changed outs:
		deleted:            .ipynb_checkpoints/data
.ipynb_checkpoints/artifacts-checkpoint.dvc:
	changed outs:
		deleted:            .ipynb_checkpoints/artifacts
[0m[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ dvc [K[K[K[Kgit status
[?2004lOn branch hacker
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mrenamed:    .github/workflows/test.yml -> .github/workflows/test.yml.tmp[m
	[32mmodified:   logs/session_logs_ga8.txt[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[32mnew file:   scripts/poison_features.py[m
	[32mnew file:   scripts/poison_labels.py[m

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   dvc.lock[m
	[31mmodified:   logs/log_push_ga8.txt[m
	[31mmodified:   logs/session_logs_ga8.txt[m

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ dvc status
[?2004l!If DVC froze, see `hardlink_lock` in <[36mhttps://man.dvc.org/config#core[39m>                                                                      !Collecting files and computing hashes in helpers/feast_utils.py                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2024.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2024.json                                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2024.joblib                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2024.json                                           |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/train_with_mlflow_tracking.py                            |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/train_2023_2024.csv                                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/metrics_2023_2024.json                                   |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in scripts/evaluate_with_mlflow_tracking.py                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/model_2023_2024.joblib                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/test_2025.csv                                               |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in metrics/eval_2023_2024.json                                      |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/label_encoder_2023_2024.joblib                         |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/feast_iris_model.joblib                                |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/feast_iris_label_encoder.joblib                        |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in artifacts/label_encoder_2023.joblib                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_sepal.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_petal.csv                                              |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/registry.db                                                 |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_sepal.parquet                                          |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_entity.csv                                             |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/online_features_iris.csv                                    |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/iris_petal.parquet                                          |0.00 [00:00,     ?file/s]                                                                                                                                    !Collecting files and computing hashes in data/online_store.db                                             |0.00 [00:00,     ?file/s]                                                                                                                                    .ipynb_checkpoints/data-checkpoint.dvc:
	changed outs:
		deleted:            .ipynb_checkpoints/data
.ipynb_checkpoints/artifacts-checkpoint.dvc:
	changed outs:
		deleted:            .ipynb_checkpoints/artifacts
[0m[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat .gitignore 
[?2004l# Ignore everything in data, artifacts, and metrics
/data/*
/artifacts/*
/metrics/*

# Allow the folders themselves
!data/
!artifacts/
!metrics/

# Allow DVC pointer files inside those folders
!data/*.dvc
!artifacts/*.dvc
!metrics/*.dvc

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim .gitignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".gitignore" 15L, 238B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Ignore everything in data, artifacts, and metrics[m
/data/*[2;8H[K[3;1H/artifacts/*[3;13H[K[4;1H/metrics/*

[34m# Allow the folders themselves[m
!data/
!artifacts/
!metrics/

[34m# Allow DVC pointer files inside those folders[m
!data/*.dvc
!artifacts/*.dvc
!metrics/*.dvc

[94m~                                                                                                                                   [17;1H~                                                                                                                                   [18;1H~                                                                                                                                   [19;1H~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H15,0-1[8CAll[15;1H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105Hi[15;1H[50;105H [15;1H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H15,1[10CAll[15;1H[?25h[?25l[16;1H[K[50;116H6[16;1H[?25h[?25l[34m#[m[50;118H2[16;2H[?25h[?25l[34m [m[50;118H3[16;3H[?25h[?25l[34mI[m[50;118H4[16;4H[?25h[?25l[34mg[m[50;118H5[16;5H[?25h[?25l[34mn[m[50;118H6[16;6H[?25h[?25l[34mo[m[50;118H7[16;7H[?25h[?25l[34mr[m[50;118H8[16;8H[?25h[?25l[34me[m[50;118H9[16;9H[?25h[?25l[34m [m[50;118H10[16;10H[?25h[?25l[34mi[m[50;119H1[16;11H[?25h[?25l[34mp[m[50;119H2[16;12H[?25h[?25l[34mp[m[50;119H3[16;13H[?25h[?25l[34my[m[50;119H4[16;14H[?25h[?25l[34mn[m[50;119H5[16;15H[?25h[?25l[16;14H[K[50;119H4[16;14H[?25h[?25l[16;13H[K[50;119H3[16;13H[?25h[?25l[16;12H[K[50;119H2[16;12H[?25h[?25l[34my[m[50;119H3[16;13H[?25h[?25l[34mb[m[50;119H4[16;14H[?25h[?25l[16;13H[K[50;119H3[16;13H[?25h[?25l[34mn[m[50;119H4[16;14H[?25h[?25l[34mb[m[50;119H5[16;15H[?25h[?25l[34m [m[50;119H6[16;16H[?25h[?25l[34mc[m[50;119H7[16;17H[?25h[?25l[34mh[m[50;119H8[16;18H[?25h[?25l[34me[m[50;119H9[16;19H[?25h[?25l[34mc[m[50;118H20[16;20H[?25h[?25l[34mk[m[50;119H1[16;21H[?25h[?25l[34mp[m[50;119H2[16;22H[?25h[?25l[34mo[m[50;119H3[16;23H[?25h[?25l[34mi[m[50;119H4[16;24H[?25h[?25l[34mn[m[50;119H5[16;25H[?25h[?25l[34mt[m[50;119H6[16;26H[?25h[?25l[34ms[m[50;119H7[16;27H[?25h[?25l
[34m# [m[17;3H[K[50;116H7,3 [17;3H[?25h[?25l[17;2H[K[50;118H2[17;2H[?25h[?25l[17;1H[K[50;118H1[17;1H[?25h[50;1H[K[17;1H[?25l[50;105H^[[17;1H[50;105H  [17;1H[50;115H17,0-1[8CAll[17;1H[?25h[?25l[50;105Hp[17;1H[50;105H [17;1H{[50;118H1  [17;1H[?25h[?25l[50;105H~@k[17;1H[50;105H   [16;26H[50;116H6,26[16;26H[?25h[?25l[50;105Hi[16;26H[50;105H [16;26H[50;1H[1m-- INSERT --[m[50;115H[K[50;115H16,26[9CAll[16;26H[?25h[?25l[50;119H7[16;27H[?25h[?25l[50;116H7,2 [17;2H[?25h[?25l[17;1H[K[50;118H1[17;1H[?25h[?25l.ipynb_checkpoints/[18;1H[K[50;116H8[18;1H[?25h[?25l[94m~                                                                                                                                   [m[50;116H7,20[17;20H[?25h[50;1H[K[17;19H[?25l[50;105H^[[17;19H[50;105H  [17;20H[50;115H17,19[9CAll[17;19H[?25h[?25l[50;105H:[17;19H[50;105H[K[50;1H:[?25hx[?25l[?1002l[?2004l[>4;m".gitignore" 17L, 285B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim .dvcignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".dvcignore" 3L, 139B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Add patterns of files dvc should ignore, which could improve
# the performance. Learn more at[m[2;33H[K[3;1H[34m# https://dvc.org/doc/user-guide/dvcignore[m[3;43H[K[4;1H[94m~                                                                                                                                   [5;1H~                                                                                                                                   [6;1H~                                                                                                                                   [7;1H~                                                                                                                                   [8;1H~                                                                                                                                   [9;1H~                                                                                                                                   [10;1H~                                                                                                                                   [11;1H~                                                                                                                                   [12;1H~                                                                                                                                   [13;1H~                                                                                                                                   [14;1H~                                                                                                                                   [15;1H~                                                                                                                                   [16;1H~                                                                                                                                   [17;1H~                                                                                                                                   [18;1H~                                                                                                                                   [19;1H~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H1,1[11CAll[1;1H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105Hj[1;1H[50;105H [2;1H[50;115H2[2;1H[?25h[?25l[50;105Hj[2;1H[50;105H [3;1H[50;115H3[3;1H[?25h[?25l[50;105Hj[3;1H[50;105H [3;1H[?25h[?25l[50;105H$[3;1H[50;105H [3;42H[50;117H42[3;42H[?25h[?25l[50;105Ha[3;42H[50;105H [3;43H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H3,43[10CAll[3;43H[?25h[?25l
[34m# [m[4;3H[K[50;115H4,3 [4;3H[?25h[?25l[4;2H[K[50;117H2[4;2H[?25h[?25l[4;1H[K[50;117H1[4;1H[?25h[?25l.ipynb_checkpoints/[5;1H[K[50;115H5[5;1H[?25h[?25l[94m~                                                                                                                                   [m[50;115H4,20[4;20H[?25h[50;1H[K[4;19H[?25l[50;105H^[[4;19H[50;105H  [4;20H[50;115H4,19[10CAll[4;19H[?25h[?25l[50;105H:[4;19H[50;105H[K[50;1H:[?25hx[?25l[?1002l[?2004l[>4;m".dvcignore" 4L, 159B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch hacker
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mrenamed:    .github/workflows/test.yml -> .github/workflows/test.yml.tmp[m
	[32mmodified:   logs/session_logs_ga8.txt[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[32mnew file:   scripts/poison_features.py[m
	[32mnew file:   scripts/poison_labels.py[m

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   .dvcignore[m
	[31mmodified:   .gitignore[m
	[31mmodified:   dvc.lock[m
	[31mmodified:   logs/log_push_ga8.txt[m
	[31mmodified:   logs/session_logs_ga8.txt[m

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim gitig[K[K[K[K[K[K.[K .gitignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".gitignore" 17L, 285B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Ignore everything in data, artifacts, and metrics[m
/data/*[2;8H[K[3;1H/artifacts/*[3;13H[K[4;1H/metrics/*

[34m# Allow the folders themselves[m
!data/
!artifacts/
!metrics/

[34m# Allow DVC pointer files inside those folders[m
!data/*.dvc
!artifacts/*.dvc
!metrics/*.dvc

[34m# Ignore ipynb checkpoints[m
.ipynb_checkpoints/
[94m~                                                                                                                                   [19;1H~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H17,19[9CAll[17;19H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105Hy[17;19H[?25h[?25l[50;106Hy[17;19H[50;105H  [17;19H[?25h[?25l[50;105Ha[17;19H[50;105H [17;20H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H17,20[9CAll[17;20H[?25h[?25l[18;1H[K[50;116H8,1 [18;1H[?25h[50;1H[K[18;1H[?25l[50;105H^[[18;1H[50;105H  [18;1H[50;115H18,0-1[8CAll[18;1H[?25h[?25l[50;105Hp[18;1H[50;105H [19;1H.ipynb_checkpoints/[19;20H[K[50;116H9,1  [19;1H[?25h[?25l[50;105H~@k[19;1H[50;105H   [18;1H[50;116H8,0-1[18;1H[?25h[?25l[50;105H~@k[18;1H[50;105H   [18;1H[50;105Hdl[18;1H[50;105H  [18;1H[?25h[?25l[50;105Hi[18;1H[50;105H [18;1H[50;1H[1m-- INSERT --[m[50;115H[K[50;115H18,1[10CAll[18;1H[?25h[?25l.ipynb_checkpoints/
[94m~                                                                                                                                   [18;1H[?25h[?25l[ms.ipynb_checkpoints/[50;118H2[18;2H[?25h[?25lc.ipynb_checkpoints/[50;118H3[18;3H[?25h[?25lr.ipynb_checkpoints/[50;118H4[18;4H[?25h[?25li.ipynb_checkpoints/[50;118H5[18;5H[?25h[?25lp.ipynb_checkpoints/[50;118H6[18;6H[?25h[?25lt.ipynb_checkpoints/[50;118H7[18;7H[?25h[?25ls.ipynb_checkpoints/[50;118H8[18;8H[?25h[?25l/.ipynb_checkpoints/[50;118H9[18;9H[?25h[50;1H[K[18;8H[?25l[50;105H^[[18;8H[50;105H  [18;9H[50;115H18,8[10CAll[18;8H[?25h[?25l[50;105H:[18;8H[50;105H[K[50;1H:[?25hx[?25l[50;2H[K[50;2H[?25h [?25l[18;8H[50;115H18,8[10CAll[18;8H[?25h[?25l[50;105H0[18;8H[50;105H [18;1H[50;118H1[18;1H[?25h[?25l[50;105H"[18;1H[?25h[?25l[50;106H+[18;1H[50;105H  [18;1H[?25h[?25l[50;105Hy[18;1H[?25h[?25l[50;106H"[18;1H[50;105H  [18;1H[?25h[?25l[50;105H+[18;1H[50;105H [18;1H[?25h[?25l[50;105Hy[18;1H[?25h[?25l[50;106Hy[18;1H[50;105H  [18;1H[?25h[?25l[50;105H:[18;1H[50;105H[K[50;1H:[?25hx[?25l[?1002l[?2004l[>4;m".gitignore" 18L, 313B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim .dvcignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".dvcignore" 4L, 159B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Add patterns of files dvc should ignore, which could improve
# the performance. Learn more at[m[2;33H[K[3;1H[34m# https://dvc.org/doc/user-guide/dvcignore[m[3;43H[K[4;1H.ipynb_checkpoints/
[94m~                                                                                                                                   [6;1H~                                                                                                                                   [7;1H~                                                                                                                                   [8;1H~                                                                                                                                   [9;1H~                                                                                                                                   [10;1H~                                                                                                                                   [11;1H~                                                                                                                                   [12;1H~                                                                                                                                   [13;1H~                                                                                                                                   [14;1H~                                                                                                                                   [15;1H~                                                                                                                                   [16;1H~                                                                                                                                   [17;1H~                                                                                                                                   [18;1H~                                                                                                                                   [19;1H~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H4,19[10CAll[4;19H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105Hy[4;19H[?25h[?25l[50;106Hy[4;19H[50;105H  [4;19H[?25h[?25l[50;105Hp[4;19H[50;105H [5;1H.ipynb_checkpoints/[5;20H[K[50;115H5,1 [5;1H[?25h[?25l[50;105Hi[5;1H[50;105H [5;1H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H5,1[11CAll[5;1H[?25h[?25ls.ipynb_checkpoints/[50;117H2[5;2H[?25h[?25lc.ipynb_checkpoints/[50;117H3[5;3H[?25h[?25lr.ipynb_checkpoints/[50;117H4[5;4H[?25h[?25li.ipynb_checkpoints/[50;117H5[5;5H[?25h[?25lp.ipynb_checkpoints/[50;117H6[5;6H[?25h[?25lt.ipynb_checkpoints/[50;117H7[5;7H[?25h[?25ls.ipynb_checkpoints/[50;117H8[5;8H[?25h[?25l/.ipynb_checkpoints/[50;117H9[5;9H[?25h[50;1H[K[5;8H[?25l[50;105H^[[5;8H[50;105H  [5;9H[50;115H5,8[11CAll[5;8H[?25h[?25l[50;105H:[5;8H[50;105H[K[50;1H:[?25hx[?25l[?1002l[?2004l[>4;m".dvcignore" 5L, 187B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git staus[K[Kts[Kus
[?2004lOn branch hacker
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mrenamed:    .github/workflows/test.yml -> .github/workflows/test.yml.tmp[m
	[32mmodified:   logs/session_logs_ga8.txt[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[32mnew file:   scripts/poison_features.py[m
	[32mnew file:   scripts/poison_labels.py[m

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   .dvcignore[m
	[31mmodified:   .gitignore[m
	[31mmodified:   dvc.lock[m
	[31mmodified:   logs/log_push_ga8.txt[m
	[31mmodified:   logs/session_logs_ga8.txt[m

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ cat .gitignore 
[?2004l# Ignore everything in data, artifacts, and metrics
/data/*
/artifacts/*
/metrics/*

# Allow the folders themselves
!data/
!artifacts/
!metrics/

# Allow DVC pointer files inside those folders
!data/*.dvc
!artifacts/*.dvc
!metrics/*.dvc

# Ignore ipynb checkpoints
.ipynb_checkpoints/
scripts/.ipynb_checkpoints/
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim giti[K[K[K[K[K .gitignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".gitignore" 18L, 313B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Ignore everything in data, artifacts, and metrics[m
/data/*[2;8H[K[3;1H/artifacts/*[3;13H[K[4;1H/metrics/*

[34m# Allow the folders themselves[m
!data/
!artifacts/
!metrics/

[34m# Allow DVC pointer files inside those folders[m
!data/*.dvc
!artifacts/*.dvc
!metrics/*.dvc

[34m# Ignore ipynb checkpoints[m
.ipynb_checkpoints/
scripts/.ipynb_checkpoints/
[94m~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H18,1[10CAll[18;1H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105Hw[18;1H[50;105H [18;8H[50;118H8[18;8H[?25h[?25l[50;105Hw[18;8H[50;105H [18;10H[50;118H10[18;10H[?25h[?25l[50;105H$[18;10H[50;105H [18;27H[50;118H27[18;27H[?25h[?25l[50;105Ha[18;27H[50;105H [18;28H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H18,28[9CAll[18;28H[?25h[?25l*[50;119H9[18;29H[?25h[50;1H[K[18;28H[?25l[50;105H^[[18;28H[50;105H  [18;29H[50;115H18,28[9CAll[18;28H[?25h[?25l[50;105HX[18;28H[50;105H [18;28H[50;105Hdh[18;28H[50;105H  [18;27H*[18;28H[K[50;119H7[18;27H[?25h[?25l[50;105H:[18;27H[50;105H[K[50;1H:[?25hx[?25l[50;2H[K[50;2H[?25h [?25l[18;27H[50;115H18,27[9CAll[18;27H[?25h[?25l[50;105H/[18;27H[50;105H[K[50;1H/[?25h [?25l[18;27H[50;115H18,27[9CAll[18;27H[?25h[?25l[50;105Hi[18;27H[50;105H [18;27H[50;1H[1m-- INSERT --[m[50;115H[K[50;115H18,27[9CAll[18;27H[?25h[?25l/*[50;119H8[18;28H[?25h[50;1H[K[18;27H[?25l[50;105H^[[18;27H[50;105H  [18;28H[50;115H18,27[9CAll[18;27H[?25h[?25l[50;105H"[18;27H[?25h[?25l[50;106Hx[18;27H[?25h[?25l[50;107H^[[18;27H[50;107H  [18;27H[50;107H^[[18;27H[50;105H    [18;27H[?25h[?25l[50;105H:[18;27H[50;105H[K[50;1H:[?25hxx[?25l[50;3H[K[50;3H[?25h[?25l[?1002l[?2004l[>4;m".gitignore" 18L, 314B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ vim .dvcignore 
[?2004l[?1000h[?1049h[22;0;0t[>4;2m[?1h=[?2004h[?1004h[1;50r[?12h[?12l[22;2t[22;1t[27m[23m[29m[m[H[2J[?25l[50;1H".dvcignore" 5L, 187B[2;1H▽[6n[2;1H  [3;1HPzz\[0%m[6n[3;1H           [1;1H[>c]10;?]11;?[1;1H[34m# Add patterns of files dvc should ignore, which could improve
# the performance. Learn more at[m[2;33H[K[3;1H[34m# https://dvc.org/doc/user-guide/dvcignore[m[3;43H[K[4;1H.ipynb_checkpoints/
scripts/.ipynb_checkpoints/
[94m~                                                                                                                                   [7;1H~                                                                                                                                   [8;1H~                                                                                                                                   [9;1H~                                                                                                                                   [10;1H~                                                                                                                                   [11;1H~                                                                                                                                   [12;1H~                                                                                                                                   [13;1H~                                                                                                                                   [14;1H~                                                                                                                                   [15;1H~                                                                                                                                   [16;1H~                                                                                                                                   [17;1H~                                                                                                                                   [18;1H~                                                                                                                                   [19;1H~                                                                                                                                   [20;1H~                                                                                                                                   [21;1H~                                                                                                                                   [22;1H~                                                                                                                                   [23;1H~                                                                                                                                   [24;1H~                                                                                                                                   [25;1H~                                                                                                                                   [26;1H~                                                                                                                                   [27;1H~                                                                                                                                   [28;1H~                                                                                                                                   [29;1H~                                                                                                                                   [30;1H~                                                                                                                                   [31;1H~                                                                                                                                   [32;1H~                                                                                                                                   [33;1H~                                                                                                                                   [34;1H~                                                                                                                                   [35;1H~                                                                                                                                   [36;1H~                                                                                                                                   [37;1H~                                                                                                                                   [38;1H~                                                                                                                                   [39;1H~                                                                                                                                   [40;1H~                                                                                                                                   [41;1H~                                                                                                                                   [42;1H~                                                                                                                                   [43;1H~                                                                                                                                   [44;1H~                                                                                                                                   [45;1H~                                                                                                                                   [46;1H~                                                                                                                                   [47;1H~                                                                                                                                   [48;1H~                                                                                                                                   [49;1H~                                                                                                                                   [m[50;115H5,8[11CAll[5;8H[?25hP+q436f\P+q6b75\P+q6b64\P+q6b72\P+q6b6c\P+q2332\P+q2334\P+q2569\P+q2a37\P+q6b31\[?1000l[?1002h[?12$p[?25l[50;105H$[5;8H[50;105H [5;27H[50;117H27[5;27H[?25h[?25l[50;105Ha[5;27H[50;105H [5;28H[50;1H[1m-- INSERT --[m[50;14H[K[50;115H5,28[10CAll[5;28H[?25h[?25l*[50;118H9[5;29H[?25h[?25l*[50;117H30[5;30H[?25h[?25l[5;29H[K[50;117H29[5;29H[?25h[50;1H[K[5;28H[?25l[50;105H^[[5;28H[50;105H  [5;29H[50;115H5,28[10CAll[5;28H[?25h[?25l[50;105H:[5;28H[50;105H[K[50;1H:[?25hx[?25l[?1002l[?2004l[>4;m".dvcignore" 5L, 188B written[23;2t[23;1t
[?1004l[?2004l[?1l>[?25h[>4;m[?1049l[23;0;0t[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git status
[?2004lOn branch hacker
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	[32mrenamed:    .github/workflows/test.yml -> .github/workflows/test.yml.tmp[m
	[32mmodified:   logs/session_logs_ga8.txt[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_features-checkpoint.py[m
	[32mnew file:   scripts/.ipynb_checkpoints/poison_labels-checkpoint.py[m
	[32mnew file:   scripts/poison_features.py[m
	[32mnew file:   scripts/poison_labels.py[m

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	[31mmodified:   .dvcignore[m
	[31mmodified:   .gitignore[m
	[31mmodified:   dvc.lock[m
	[31mmodified:   logs/log_push_ga8.txt[m
	[31mmodified:   logs/session_logs_ga8.txt[m

[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ [H[2J(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git as[Kdd .
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git commit -m "Checked everything beffore [K[K[K[K[Kore poisoning"
[?2004l[hacker 9307eca] Checked everything before poisoning
 10 files changed, 655 insertions(+), 24 deletions(-)
 rename .github/workflows/{test.yml => test.yml.tmp} (100%)
 create mode 100644 scripts/.ipynb_checkpoints/poison_features-checkpoint.py
 create mode 100644 scripts/.ipynb_checkpoints/poison_labels-checkpoint.py
 create mode 100644 scripts/poison_features.py
 create mode 100644 scripts/poison_labels.py
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git pu[K[K[K[K[K[Kgit status
[?2004lOn branch hacker
nothing to commit, working tree clean
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git o[Kpush origin hacker
[?2004lEnumerating objects: 25, done.
Counting objects:   4% (1/25)Counting objects:   8% (2/25)Counting objects:  12% (3/25)Counting objects:  16% (4/25)Counting objects:  20% (5/25)Counting objects:  24% (6/25)Counting objects:  28% (7/25)Counting objects:  32% (8/25)Counting objects:  36% (9/25)Counting objects:  40% (10/25)Counting objects:  44% (11/25)Counting objects:  48% (12/25)Counting objects:  52% (13/25)Counting objects:  56% (14/25)Counting objects:  60% (15/25)Counting objects:  64% (16/25)Counting objects:  68% (17/25)Counting objects:  72% (18/25)Counting objects:  76% (19/25)Counting objects:  80% (20/25)Counting objects:  84% (21/25)Counting objects:  88% (22/25)Counting objects:  92% (23/25)Counting objects:  96% (24/25)Counting objects: 100% (25/25)Counting objects: 100% (25/25), done.
Delta compression using up to 2 threads
Compressing objects:   7% (1/13)Compressing objects:  15% (2/13)Compressing objects:  23% (3/13)Compressing objects:  30% (4/13)Compressing objects:  38% (5/13)Compressing objects:  46% (6/13)Compressing objects:  53% (7/13)Compressing objects:  61% (8/13)Compressing objects:  69% (9/13)Compressing objects:  76% (10/13)Compressing objects:  84% (11/13)Compressing objects:  92% (12/13)Compressing objects: 100% (13/13)Compressing objects: 100% (13/13), done.
Writing objects:   7% (1/14)Writing objects:  14% (2/14)Writing objects:  21% (3/14)Writing objects:  28% (4/14)Writing objects:  35% (5/14)Writing objects:  42% (6/14)Writing objects:  50% (7/14)Writing objects:  57% (8/14)Writing objects:  64% (9/14)Writing objects:  71% (10/14)Writing objects:  78% (11/14)Writing objects:  85% (12/14)Writing objects:  92% (13/14)Writing objects: 100% (14/14)Writing objects: 100% (14/14), 13.57 KiB | 1.70 MiB/s, done.
Total 14 (delta 8), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas:   0% (0/8)[Kremote: Resolving deltas:  12% (1/8)[Kremote: Resolving deltas:  25% (2/8)[Kremote: Resolving deltas:  37% (3/8)[Kremote: Resolving deltas:  50% (4/8)[Kremote: Resolving deltas:  62% (5/8)[Kremote: Resolving deltas:  75% (6/8)[Kremote: Resolving deltas:  87% (7/8)[Kremote: Resolving deltas: 100% (8/8)[Kremote: Resolving deltas: 100% (8/8), completed with 6 local objects.[K
To https://github.com/ganeshbmc/MLOps_1.git
   5ad5d42..9307eca  hacker -> hacker
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git checkout main
[?2004lerror: Your local changes to the following files would be overwritten by checkout:
	logs/session_logs_ga8.txt
Please commit your changes or stash them before you switch branches.
Aborting
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git [K[K[K[Kgit add .
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git co[K[K[K[K[K[Khistory 
[?2004l   35  git commmit -m "Modified test files to point to correct file paths"
   36  git push origin dev
   37  git status
   38  git commit -m "Modified test files to point to correct file paths"
   39  git push origin dev
   40  dvc list .
   41  dvc list -R .
   42  dvc list . --dvc-only -R
   43  dvc status
   44  dvc status -c
   45  cat .gitignore 
   46  vim .gitignore 
   47  git status
   48  vim .gitignore 
   49  dvc status
   50  dvc add .
   51  dvc status --untracked
   52  dvc status --untracked . -R
   53  dvc status --untracked data
   54  dvc status --untracked ./data
   55  dvc status
   56  dvc add artifacts/feast_iris_model.joblib artifacts/feast_iris_label_encoder.joblib artifacts/label_encoder_2023_2024.joblib
   57  dvc add artifacts/label_encoder_2023.joblib artifacts/model_2023_2024.joblib artifacts/model_2023.joblib artifacts/model_2024.joblib 
   58  dvc add artifacts/label_encoder_2023.joblib
   59  dvc status
   60  git status
   61  git add .
   62  git status
   63  dvc add data/iris_entity.csv data/iris_petal.csv data/iris_petal.parquet data/iris_sepal.csv data/iris_sepal.parquet data/online_features_iris.csv 
   64  dvc add data/test_2025.csv 
   65  dvc status
   66  git status
   67  echo "$(date) - Changed gitignore file and added specific files to be tracked by dvc
   68  "
   69  echo "$(date) - Changed gitignore file and added specific files to be tracked by dvc" >> log_push.txt 
   70  cat log_push.txt 
   71  git status
   72  git add ..
   73  git add .
   74  git status
   75  cat log_push.txt 
   76  git commit -m "Changed gitignore file and added specific files to be tracked by dvc"
   77  git status
   78  git push origin dev
   79  git status
   80  echo "$(date) - Modified test file again and changed back the file path to be relative to root"
   81  echo "$(date) - Modified test file again and changed back the file path to be relative to root" >> log_push.txt 
   82  git status
   83  git add .
   84  git commit -m "Modified test file again and changed back the file path to be relative to root"
   85  git push origin dev
   86  conda deactivate
   87  ls
   88  cd iris_pipeline/
   89  cat docker_demo/fastapi_iris.py 
   90  script logs/session_logs_ga7.txt
   91  conda activate iris_env_c
   92  git status
   93  echo "$(date) - Checking week 6 CI/CD pipeline before proceeding to week 7 set up"
   94  sudo timedatectl set-timezone Asia/Kolkata
   95  echo "$(date) - Checking week 6 CI/CD pipeline before proceeding to week 7 set up"
   96  echo "$(date) - Checking week 6 CI/CD pipeline before proceeding to week 7 set up." >> logs/log_push_ga7.txt
   97  git status
   98  git add .
   99  git commit -m "Organized the log files into log folder and renamed them week wise."
  100  git push origin main
  101  git pull origin main
  102  git push origin main
  103  git status
  104  git checkout dev
  105  git add .
  106  git commit -m "minor changes to log file"
  107  git push origin main
  108  git checkout dev
  109  git status
  110  git add .
  111  git commit -m "minor changes to sesion log"
  112  git push origin main
  113  git checkout dev
  114  git status
  115  git status
  116  git pull origin dev
  117  git merge main
  118  git push origin dev
  119  git status
  120  git add .
  121  git status
  122  git status
  123  git status
  124  echo "$(date) - Was working on main instead of dev. Now switched to dev. Checking week 6 pipeline."
  125  echo "$(date) - Was working on main instead of dev. Now switched to dev. Checking week 6 pipeline." >> logs/log_push_ga7.txt 
  126  git status
  127  git add .
  128  git commit -m "Pushing log to check week 6 CI/CD pipeline"
  129  git push origin dev
  130  cd observability_demo/
  131  cp ../docker_demo/fastapi_iris.py .
  132  ls
  133  ls -larth ../docker_demo/
  134  cp ../docker_demo/feast_iris_model.joblib ../docker_demo/feast_iris_label_encoder.joblib ../docker_demo/Dockerfile ../docker_demo/requirements.txt .
  135  ls -larth
  136  mv fastapi_iris.py demo_log.py
  137  ls -larth
  138  ls -larth
  139  git status
  140  cd ..
  141  git status
  142  git add .
  143  git commit -m "Created new folder for week 7 work on monitoring, logging, trace and observability. Added the files. Need to check and edit one by one."
  144  git satus
  145  git status
  146  conda activate iris_env_c
  147  docker images
  148  docker build -t iris-api-log-demo .
  149  cd observability_demo/
  150  docker build -t iris-api-log-demo .
  151  docker images
  152  docker run -d -p 8200:8200 iris-api-log-demo
  153  docker logs
  154  docker logs 4e8bda1fe4836d36e6f4c412251b7003e2870386098b8668c72995459a4fe2f4
  155  docker build -t iris-api-log-demo .
  156  docker images
  157  docker run -d -p 8200:8200 iris-api-log-demo
  158  docker logs ac8c7ead5c6fedc8e7ad0c503b9da7d522d81808ee008d233740178d67620168
  159  docker ps
  160  docker buid -t iris-api-log-demo .
  161  docker build -t iris-api-log-demo .
  162  docker images
  163  docker run -d -p 8200:8200 iris-api-log-demo
  164  docker logs 3732e0d735a1efd4d49d332972bcb072ecb618ceaeac217e6c0f81949975d108
  165  docker build -t iris-api-log-demo .
  166  docker run -d -p 8200:8200 iris-api-log-demo
  167  docker logs e18aa7bf21ccaa006fde40fa06d18761751578ca8bebf961fde5c574146db8c5
  168  python3 demo_log_iris_app.py 
  169  python3 demo_log_iris_app.py 
  170  docker build -t iris-api-log-demo .
  171  docker run -d -p 8200:8200 iris-api-log-demo
  172  docker logs 4d67e19c6e5436bd99f8fac63268d88fa97c5f5209875f3d6d42c49bcd3fddc0
  173  docker build -t iris-api-log-demo .
  174  docker run -d -p 8200:8200 iris-api-log-demo
  175  docker logs bd345eb728520524ed425a60601e114c65cd7717b340b33b49b7406838dc55e2
  176  git status
  177  git add .
  178  docker build -t iris-api-log-demo .
  179  docker build -t iris-api-log-demo .
  180  docker run -d -p 8200:8200 iris-api-log-demo
  181  docker ps
  182  docker stop heuristic_matsumoto
  183  docker ps
  184  docker run -d -p 8200:8200 iris-api-log-demo
  185  docker logs ad36afc78b0bab823b62dcd0d7dc01dd4655379fd23f50f2a6b62aecc0357b14
  186  git status
  187  git add .
  188  git commit -m "Docker up and running after file edits in observability_demo files. Checked GET/PUSH calls."
  189  git push origin dev
  190  conda deactivate
  191  exit
  192  pwd
  193  git status
  194  cd iris_pipeline/
  195  git status
  196  script -a logs/session_logs_ga7.txt 
  197  git status
  198  exit
  199  conda activate iris_env_c
  200  $date
  201  date
  202  echo "($date) - hi"
  203  echo "$(date) - hi"
  204  echo "$(date) - Checking github actions set up in week 5. Remember that GitHub Actions does not use file from observabiliyt_demo yet." >> logs/log_push_ga7.txt 
  205  cat logs/log_push_ga7.txt 
  206  git status
  207  git add .
  208  git commit -m "Checking github actions set up in week 5. Remember that GitHub Actions does not use file from observabiliyt_demo yet."
  209  git push origin dev
  210  echo "$(date) - check docker image built for week 7 GA, run it and check if it works."
  211  ip addr show
  212  curl ifconfig.me
  213  docker images
  214  docker run -d -p 8200:8200 iris-api-log-demo 
  215  curl ifconfig.me
  216  docker ps
  217  docker logs 6245d89e49c8ff5b1dd5bb19ce0ce0ecc6ca68855ba8bc1db2a565932c4900df
  218  docker logs 6245d89e49c8ff5b1dd5bb19ce0ce0ecc6ca68855ba8bc1db2a565932c4900df
  219  docker stop hungry_pike
  220  docker ps
  221  docker tag iris-api-log-demo us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api-log-demo:latest
  222  docker push us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api-log-demo:latest
  223  echo "$(date) - Docker image pushed to artifact registry in us-central1 location."
  224  echo "$(date) - Now we will set up a new kubernetes cluster on GKE asia-southeast1 region with 5 pods using commanline (kubectl)."
  225  gcloud container clusters create demo-log-ml-cluster --zone=asia-southeast1-a --num-nodes=3 --workload-pool=$(gcloud config get-value project).svc.id.goog --logging=SYSTEM,WORKLOAD --monitoring=SYSTEM
  226  pwd
  227  echo "$(date) - K8s cluster named demo-log-ml-cluster created in asia-southeast1-a zone and verified on GCP using UI."
  228  echo "$(date) - Before deploying the workloads, will enbale few gcloud services for logging, monitoring and tracing to work."
  229  2.	gcloud services enable container.googleapis.com     logging.googleapis.com     monitoring.googleapis.com     cloudtrace.googleapis.com
  230  gcloud services enable container.googleapis.com     logging.googleapis.com     monitoring.googleapis.com     cloudtrace.googleapis.com
  231  echo "$(date) - Set the context for K8s cluster named demo-log-ml-cluster so that kubectl commands will work on this specific cluster."
  232  gcloud container clusters get-credentials demo-log-ml-cluster
  233  gcloud container clusters get-credentials demo-log-ml-cluster --zone=asia-southeast1-a
  234  echo "$(date) - Check the nodes, pods and services in the demo-log-ml-cluster cluster."
  235  kubectl get nodes
  236  kubectl get pods
  237  kubectl get services
  238  echo "$(date) - Create service account for telemetry-access (same name mentioned in the deployment.yaml file) and add I AM roles to enable logging and cloudtrace."
  239  gcloud iam service-accounts create telemetry-access --display-name "Access for GKE ML service"
  240  PROJECT_ID=$(gcloud config get-value project)
  241  echo $(PROJECT_ID)
  242  echo $PROJECT_ID
  243  gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:telemetry-access@$PROJECT_ID.iam.gserviceaccount.com" --role="roles/logging.logWriter"
  244  gcloud projects add-iam-policy-binding polar-pillar-461115-g2     --member="serviceAccount:831589306777-compute@developer.gserviceaccount.com"     --role="roles/resourcemanager.projectIamAdmin"
  245  gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:telemetry-access@$PROJECT_ID.iam.gserviceaccount.com" --role="roles/logging.logWriter"
  246  gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:telemetry-access@$PROJECT_ID.iam.gserviceaccount.com" --role="roles/cloudtrace.agent"
  247  gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:telemetry-access@$PROJECT_ID.iam.gserviceaccount.com" --role="roles/monitoring.metricWriter"
  248  gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:telemetry-access@$PROJECT_ID.iam.gserviceaccount.com" --role="roles/logging.logWriter"
  249  echo "$(date) - Everytime a GKE cluster is created, a kubernetes service account needs to be created and mapped to the Google cloud service acccount so that the two system users can talk to each other."
  250  kubectl create service account telemetry-access --namespace default
  251  kubectl create serviceaccount telemetry-access --namespace default
  252  echo "$(date) - K8s service account is created. Next is mapping to google cloud service account which is also called annotation."
  253  kubectl annotate serviceaccount telemetry-access --namespace default iam.gke.io/gcp-service-account=telemetry-access@$PROJECT_ID.iam.gserviceaccount.com
  254  gcloud iam service-accounts add-iam-policy-binding telemetry-access@$PROJECT_ID.iam.gserviceaccount.com --role roles/iam.workloadIdentityUser --member "serviceAccount:$PROJECT_ID.svc.id.goog[default/telemetry-access]"
  255  echo "$(date) - This error is probably because I am already logged in and it is already set up for me."
  256  echo "$(date) - Now the mapping or annotation of K8s service account to google cloud service account is complete. Now, the telemetry-access service account will be automatically used by the k8s cluster to log information to the various google cloud services like logging, monitoring, tracing we will use."
  257  echo "$(date) - Confirm that the service accounts set up and mapping/annotation works correctly."
  258  kubectl -h
  259  kubectl cluster-info
  260  kubectl config current-context
  261  kubectl get serviceaccount telemetry-access -n default
  262  kubectl describe serviceaccount telemetry-access -n default 
  263  gcloud iam service-accounts get-iam-policy telemetry-access@$PROJECT_ID.iam.gserviceaccount.com
  264  gcloud projects add-iam-policy-binding polar-pillar-461115-g2     --member="serviceAccount:telemetry-access@polar-pillar-461115-g2.iam.gserviceaccount.com"     --role="roles/logging.logWriter"
  265  gcloud iam service-accounts get-iam-policy telemetry-access@$PROJECT_ID.iam.gserviceaccount.com
  266  gcloud iam service-accounts add-iam-policy-binding telemetry-access@$PROJECT_ID.iam.gserviceaccount.com   --role roles/iam.workloadIdentityUser   --member "serviceAccount:$PROJECT_ID.svc.id.goog[default/telemetry-access]"
  267  gcloud iam service-accounts get-iam-policy telemetry-access@$PROJECT_ID.iam.gserviceaccount.com
  268  gcloud auth login
  269  gcloud iam service-accounts add-iam-policy-binding telemetry-access@$PROJECT_ID.iam.gserviceaccount.com   --role roles/iam.workloadIdentityUser   --member "serviceAccount:$PROJECT_ID.svc.id.goog[default/telemetry-access]"
  270  gcloud iam service-accounts get-iam-policy telemetry-access@$PROJECT_ID.iam.gserviceaccount.com
  271  echo "$(date) - Now the mapping or annotation of K8s service account to google cloud service account is complete. Now, the telemetry-access service account will be automatically used by the k8s cluster to log information to the various google cloud services like logging, monitoring, tracing we will use."
  272  echo "$(date) - Mapping or annotation of K8s service account to google cloud service account is verified."
  273  echo "$(date) - We can now deploy the Docker image which is already available in the artifacts registry. We will use the deployment.yaml file for this."
  274  kubectl apply -f deployment.yaml
  275  cd observability_demo/
  276  kubectl apply -f deployment.yaml
  277  echo "$(date) - Next we can deploy the other manifests like the service.yaml and hpa.yaml."
  278  kubectl apply -f service.yaml
  279  kubectl apply -f hpa.yaml 
  280  echo "$(date) - Check the external IP address that is going to be exposed by the K8s cluster."
  281  kubectl get service demo-log-ml-service
  282  pwd
  283  cd ..
  284  cd observability_demo/
  285  docker images
  286  docker build -t iris-api-log-demo .
  287  docker tag iris-api-log-demo us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api-log-demo:latest
  288  docker push us-central1-docker.pkg.dev/polar-pillar-461115-g2/my-repo/iris-api-log-demo:latest
  289  kubectl rollout restart deployment demo-log-ml-service
  290  echo "$(date) - Deployment to k8s successful. Tested with Postman. Checked logging, trace to make sure everything is working as expected."
  291  echo "$(date) - Next is to load test it. Install wrk and test."
  292  sudo apt-get install wrk
  293  vim post.lua
  294  cat post.lua 
  295  wrk -t4 -c100 -d30s --latency -s post.lua http://34.124.181.99/predict
  296  vim post.lua
  297  vim post.lua
  298  vim post.lua
  299  rm -f post.lua.swp
  300  vim post.lua
  301  rm -f .post.lua.swp
  302  vim post.lua
  303  wrk -t4 -c100 -d5s --latency -s post.lua http://34.124.181.99/predict
  304  kubectl get service demo-log-ml-service
  305  wrk -t4 -c100 -d5s --latency -s post.lua http://34.124.181.99/predict/
  306  wrk -t4 -c100 -d5s --latency -s post.lua http://34.124.181.99/predict/
  307  wrk -t4 -c100 -d300s --latency -s post.lua http://34.124.181.99/predict/
  308  wrk -t12 -c400 -d30s --latency -s post.lua http://34.124.181.99/predict/
  309  pwd
  310  git status
  311  git add .
  312  git commit -m "Week 7 GA complete"
  313  kubectl get service demo-log-ml-service
  314  echo "$(date) - The following commands will be part of the demo video for GA7 MLOps course."
  315  wrk -t12 -c400 -d10s --latency -s post.lua http://34.124.181.99/predict/
  316  echo "$(date) - Successfully completed week 7 demo. No changes to github actions."
  317  echo "$(date) - Successfully completed week 7 demo. No changes to github actions." >> ../logs/log_push_ga7.txt 
  318  cat ../logs/log_push_ga77
  319  cat ../logs/log_push_ga7.txt 
  320  git add .
  321  git commit -m "Successfully completed week 7 demo. No changes to github actions."
  322  git push origin devv
  323  git push origin dev
  324  exit
  325  conda deactivate
  326  exit
  327  exit
  328  git status
  329  script -a logs/session_logs_ga7.txt 
  330  git status
  331  git add .
  332  git commit -m "Successfully completed week 7 demo. No changes to github actions. Minor changes in log files added."
  333  git push origin dev
  334  exit
  335  ls
  336  cat logs/log_push_ga7.txt 
  337  date
  338  git status
  339  git add .
  340  git status
  341  git commit -m "No updates. Just pushing to check everything is in place."
  342  git push origin dev
  343  git checkout main
  344  git pull origin main
  345  git merge dev
  346  git push origin main
  347  dvc list
  348  dvc list --dvc-only .
  349  dvc status
  350  dvc repro evaluate_2023
  351  dvc repro train_2023
  352  dvc repro evaluate_2023
  353  dvc repro --force
  354  conda activate iris_env_c
  355  dvc repro --force
  356  conda deactivate
  357  script logs/session_logs_ga8.txt
  358  conda activate iris_env_c
  359  echo "($date) - Week 8 GA begins. Let us check git status before proceeding."
  360  echo "$(date) - Week 8 GA begins. Let us check git status before proceeding."
  361  touch logs/log_push_ga8.txt
  362  cat logs/log_push_ga8.txt 
  363  echo "$(date) - Week 8 GA begins. Let us check git status before proceeding." >> logs/log_push_ga8.txt 
  364  cat logs/log_push_ga8.txt 
  365  git status
  366  echo "$(date) - Rest of the work will be done on branch named 'hacker'. This branch will be from main branch at commit d96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th which is the final commit for GA5. Idea is start GA8 from this stage as GA6 and GA7 were different and ran from separate folder except for the github actions test.yml file."
  367  echo "$(date) - Rest of the work will be done on branch named 'hacker'. This branch will be from main branch at commit d96f15b44460672cd7da64ee74e90e987d7f7498 on Jul 6th which is the final commit for GA5. Idea is start GA8 from this stage as GA6 and GA7 were different and ran from separate folder except for the github actions test.yml file." >> logs/log_push_ga8.txt 
  368  cat logs/log_push_ga8.txt 
  369  git status
  370  git add .
  371  git commit -m "Updating main before forking a new branch 'hacker' for GA8."
  372  git push origin main
  373  git log --oneline
  374  git checkout -b hacker d96f15b44460672cd7da64ee74e90e987d7f7498
  375  git add .
  376  git commit -m "minor changes"
  377  git push origin main
  378  git checkout -b hacker d96f15b44460672cd7da64ee74e90e987d7f7498
  379  git push origin hacker
  380  vim .github/workflows/test.yml 
  381  git status
  382  git push origin hacker
  383  git add .
  384  git commit -m "Added workflow_dispatch to test.yml actions workflow file to enable manual triggering of github action."
  385  git push origin hacker
  386  mv .github/workflows/test.yml .github/workflows/hacker_ci_cml_ga8.yml
  387  ls .github/workflows/
  388  cat .github/workflows/hacker_ci_cml_ga8.yml 
  389  git status
  390  git add .
  391  git commit -m "Renamed the GitHub Actions Workflow yml file to see if the Action shows up on GitHub repo for manual trigger."
  392  git push origin hacker
  393  gh workflow run "CI with CML" --ref hacker
  394  pip install gh
  395  gh workflow run "CI with CML" --ref hacker
  396  pip uninstall gh
  397  sudo apt install gh
  398  sudo snap install gh
  399  sudo apt update
  400  sudo apt install snap
  401  sudo snap install gh
  402  sudo apt install snapd -y
  403  snap version
  404  sudo snap install gh
  405  gh --version
  406  sudo reboot
  407  conda activate iris_env_c
  408  gh --version
  409  gh auth login
  410  sudo snap remove gh
  411  sudo apt update
  412  sudo apt install gh -y
  413  # 1. Remove any broken/missing packages
  414  sudo apt clean
  415  sudo apt update
  416  # 2. Install GitHub CLI from GitHub's official apt repo
  417  # Add keyring
  418  curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg |   sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
  419  sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg
  420  # Add the GitHub CLI repo
  421  echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" |   sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
  422  # Update and install gh
  423  sudo apt update
  424  sudo apt install gh -y
  425  gh --version
  426  which gh
  427  sudo snap remove gh
  428  hash -r
  429  which gh
  430  gh --version
  431  gh workflow run "CI with CML" --ref hacker
  432  gh auth login
  433  gh workflow run "CI with CML" --ref hacker
  434  git status
  435  cat .github/workflows/hacker_ci_cml_ga8.yml 
  436  gh workflow list
  437  gh workflow run hacker_ci_cml_ga8.yml --ref hacker
  438  git checkout main
  439  git status
  440  git add .
  441  git commit -m "minor changes"
  442  git checkout main
  443  git checkout hacker -- .github/workflows/hacker_ci_cml_ga8.yml
  444  git add .github/workflows/hacker_ci_cml_ga8.yml 
  445  git commit -m "Add CI with CML workflow from hacker branch"
  446  git push origin main
  447  git status
  448  git checkout hacker
  449  gh workflow run "CI with CML" --ref hacker
  450  cat .github/workflows/hacker_ci_cml_ga8.yml 
  451  git status
  452  git checkout main
  453  git pull origin main
  454  git checkout -b dummy
  455  git touch dummy.txt
  456  git add .
  457  git status
  458  cat dummy.txt 
  459  git add .
  460  git status
  461  vim dummy.txt 
  462  git add .
  463  git status
  464  git commit -m "Dummy branch, dummy commit, to trigger action on PR"
  465  git push origin dummy
  466  dvc status
  467  git checkout main
  468  dvc status
  469  dvc push
  470  git checkout dummy
  471  vim dummy.txt 
  472  git add .
  473  git status
  474  git commit -m "another dummy push for PR"
  475  git push origin dummy
  476  git checkout hacker
  477  git status
  478  conda deactivate
  479  exit
  480  cd iris_pipeline/
  481  git status
  482  script session_logs_ga8.txt
  483  ls
  484  git sattus
  485  git status
  486  git branch -d hacker
  487  git checkout main
  488  git branch -d hacker
  489  git branch -D hacker
  490  git push --delete hacker
  491  git push origin --delete hacker
  492  ls -larth
  493  git tag pre-poisoned
  494  git tag -d pre-poisoned 
  495  git tag -a pre-poisoned -m "This is the state of the repo before data poisoning"
  496  git tag
  497  git push origin pre-poisoned 
  498  git checkout -b hacker
  499  git status
  500  git push origin hacker
  501  conda activate iris_env_c
  502  git status
  503  dvc repro
  504  mv .github/workflows/test.yml .github/workflows/test.yml.tmp
  505  ls .github/workflows/
  506  git status
  507  cat .github/workflows/test.yml.tmp 
  508  git add .
  509  echo "$(data) - Check dvc pipeline, mlflow tracking before poisoning data."
  510  echo "$(date) - Check dvc pipeline, mlflow tracking before poisoning data."
  511  echo "$(date) - Check dvc pipeline, mlflow tracking before poisoning data." >> logs/log_push_ga8.txt 
  512  git status
  513  dvc repro --force
  514  dvc status
  515  git status
  516  dvc status
  517  cat .gitignore 
  518  vim .gitignore 
  519  vim .dvcignore 
  520  git status
  521  vim .gitignore 
  522  vim .dvcignore 
  523  git status
  524  cat .gitignore 
  525  vim .gitignore 
  526  vim .dvcignore 
  527  git status
  528  git add .
  529  git commit -m "Checked everything before poisoning"
  530  git status
  531  git push origin hacker
  532  git checkout main
  533  git add .
  534  history 
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ 529
[?2004lbash: 529: command not found
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ 529history git add .checkout mainpush origin hacker[12Pstatuscommit -m "Checked everything before poisoning" "-" "m"i"n"o"r" "c"n"[1P"h"a"n"g"e"s"
[?2004l[hacker 772d381] Checked everything before poisoning - minor changes
 1 file changed, 37 insertions(+), 1 deletion(-)
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ g[Kgit checkout mainn
[?2004lerror: pathspec 'mainn' did not match any file(s) known to git
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git checkout mainn[K
[?2004lerror: Your local changes to the following files would be overwritten by checkout:
	logs/session_logs_ga8.txt
Please commit your changes or stash them before you switch branches.
Aborting
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git checkout mainnommit -m "Checked everything before poisoning - minor changes"[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C529[Khistory git add .
[?2004l[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git add .checkout mainnommit -m "Checked everything before poisoning - minor changes"[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C529[Kgit commit -m "Checked everything before poisoning - minor changes"a"g" [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca"i"n"[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C again"[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[C[C[C[C
[?2004l[hacker 991baff] Checked everything before poisoning - minor changes again
 1 file changed, 486 insertions(+), 1 deletion(-)
[?2004h(iris_env_c) jupyter@instance-20250527-224052:~/iris_pipeline$ git commit -m "Checked everything before poisoning - minor changes again"[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C